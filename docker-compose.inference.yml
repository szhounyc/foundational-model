services:
  # Inference Service with correct name for backend compatibility
  inference-service:
    build:
      context: ./inference-service
      dockerfile: Dockerfile
    container_name: contract-inference-service
    ports:
      - "9200:9200"
    volumes:
      - ./models:/app/models:ro
      - ./dataset:/app/dataset:ro
    environment:
      - PYTHONPATH=/app
      - TOKENIZERS_PARALLELISM=false
      - FIREWORKS_API_KEY=${FIREWORKS_API_KEY}
      - MODELS_DIR=/app/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9200/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
    restart: unless-stopped
    networks:
      - contract-review-network

networks:
  contract-review-network:
    driver: bridge 